{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import linalg\n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.spatial.distance import squareform\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for testing CAD methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN (for conformal score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cuda library to run knn (much faster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNearestNeighbors():\n",
    "    \"\"\"\n",
    "        A simple real-valued function to compute the conformal scores\n",
    "        Each conformal score is the average k-nearest neighbors according to a specified metric\n",
    "        @params\n",
    "            k: int\n",
    "                Determines k nearest neighbors\n",
    "            metric: str\n",
    "                distance metric (see scipy's pdist function for valid metrics)\n",
    "    \"\"\"\n",
    "    def __init__(self,k,metric='euclidean'):\n",
    "        self._k = k\n",
    "        self._metric = metric\n",
    "\n",
    "    \"\"\"\n",
    "        Returns a pairwise distance matrix\n",
    "        @params\n",
    "            x: np.ndarray\n",
    "                An m x n array with m samples and n dimensions\n",
    "    \"\"\"\n",
    "    def get_pairwise_distance_matrix(self,x):\n",
    "        distances = pdist(x,self._metric)\n",
    "        distance_matrix = squareform(distances)\n",
    "        return distance_matrix\n",
    "\n",
    "    \"\"\"\n",
    "        Returns the mean pairwise distance between the k'th nearest neighbors\n",
    "        @params\n",
    "            x: np.ndarray\n",
    "                An m x n array with m samples and n dimensions\n",
    "    \"\"\"\n",
    "    def __call__(self,x):\n",
    "        distance_matrix = self.get_pairwise_distance_matrix(x)\n",
    "        distance_matrix = np.sort(distance_matrix,axis=1)\n",
    "        assert self._k +1 < distance_matrix.shape[1],\\\n",
    "            print('K must be less than the number of data points (k={},num_samples={})'.format(self._k +1,distance_matrix.shape[1]))\n",
    "        return np.mean(distance_matrix[:,1:self._k+1],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AbsDistanceFromMedian():\n",
    "    def get_distance(self, x):\n",
    "        med = np.median(x)\n",
    "        distance = abs(x - med)\n",
    "        return distance\n",
    "    def __call__(self, x):\n",
    "        distance = self.get_distance(x)\n",
    "        return distance\n",
    "\n",
    "class DistanceFromMedian():\n",
    "    def get_distance(self, x):\n",
    "        med = np.median(x)\n",
    "        distance = x - med\n",
    "        return distance\n",
    "    def __call__(self, x):\n",
    "        distance = self.get_distance(x)\n",
    "        return distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table including confidence (histogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConformalAnomalyDetector():\n",
    "    \"\"\"\n",
    "    Conformal Anomaly Detector Class\n",
    "    @params\n",
    "        ICM: class\n",
    "            An object whose call operation should produce an array of conformal scores\n",
    "        z: tuple (len==2)\n",
    "            Each element is an (x,y) pair of the training set for CAD\n",
    "        significance: float\n",
    "            The significance level (must be between 0 and 1 exclusive)\n",
    "    \"\"\"\n",
    "    # def __init__ (self,ICM,x,significance=0.05):\n",
    "    #     self._ICM = ICM\n",
    "    def __init__ (self,ICM,x,significance=0.05):\n",
    "        self._ICM = ICM\n",
    "        self.x = x\n",
    "        # self.y = z[1]\n",
    "        assert significance > 0 and significance < 1, \\\n",
    "            print('Significance must be in range (0,1).')\n",
    "        self._significance = significance\n",
    "        \n",
    "    \"\"\"\n",
    "    Return true or false if the test example are an anomaly\n",
    "    @params\n",
    "        test: np.ndarray\n",
    "            A 1xn test example where m is the number of test examples and n is the number of dimensions\n",
    "    @return: bool\n",
    "        True if test input is anomaly and false otherwise \n",
    "    \"\"\"\n",
    "    def testIfAnomaly(self,test):\n",
    "        conformal_set = np.concatenate((self.x,test))\n",
    "        conformal_scores = self._ICM(conformal_set)\n",
    "        p = np.sum(conformal_scores >= conformal_scores[-1]) / (len(self.x)+1)\n",
    "        return p < self._significance\n",
    "\n",
    "    \"\"\"\n",
    "    Return array of true or false if the test examples are an anomaly\n",
    "    @params\n",
    "        test: np.ndarray\n",
    "            A mxn test example where m is the number of test examples and n is the number of dimensions\n",
    "    @return: np.ndarray\n",
    "        An mx1 array of true if test input is anomaly and false otherwise \n",
    "    \"\"\" \n",
    "    def __call__(self,anomalies):\n",
    "        isAnomaly = [self.testIfAnomaly(np.expand_dims(anomalies[i],axis=0)) for i in range(anomalies.shape[0])]\n",
    "        return isAnomaly\n",
    "\n",
    "    \"\"\"\n",
    "    Change significance level (hyper-parameter)\n",
    "    @params\n",
    "        significance: float\n",
    "            The significance level (must be between 0 and 1 exclusive)\n",
    "    \"\"\" \n",
    "    def set_significance(self,significance):\n",
    "        assert significance > 0 and significance < 1, \\\n",
    "            print('Significance must be in range (0,1).')\n",
    "        self._significance = significance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FGSM4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"output/base_loss.pkl\", \"rb\") as f:\n",
    "    base_loss_values = pickle.load(f)\\\n",
    "\n",
    "with open(\"output/fgsm4_mixed2.pkl\", \"rb\") as f:\n",
    "    fgsm4_mixed = pickle.load(f)\n",
    "\n",
    "with open(\"output/fgsm4_loss.pkl\", \"rb\") as f:\n",
    "    fgsm4_clean = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k_nearest_neighbor = KNearestNeighbors(k=1)\n",
    "medAbsDistance = AbsDistanceFromMedian()\n",
    "\n",
    "train = np.array(base_loss_values).reshape(len(base_loss_values), 1)\n",
    "\n",
    "# conformal_predictor = ConformalAnomalyDetector(ICM=k_nearest_neighbor, x=train)\n",
    "conformal_predictor = ConformalAnomalyDetector(ICM=medAbsDistance, x=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "conformal_predictor.set_significance(0.30)\n",
    "\n",
    "test = np.array(fgsm4_mixed).reshape(len(fgsm4_mixed), 1)\n",
    "is_outlier = conformal_predictor(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP 14996\n",
      "TN 35004\n",
      "FN 15666\n",
      "TP 34334\n"
     ]
    }
   ],
   "source": [
    "print(\"FP\", sum(is_outlier[0:len(base_loss_values)]))\n",
    "print(\"TN\", len(base_loss_values) - sum(is_outlier[0:len(base_loss_values)]))\n",
    "print(\"FN\", len(fgsm4_clean) - sum(is_outlier[len(base_loss_values):]))\n",
    "print(\"TP\", sum(is_outlier[len(base_loss_values):]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.69338\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy\", (sum(is_outlier[len(base_loss_values):]) + len(base_loss_values) - sum(is_outlier[0:len(base_loss_values)])) / len(fgsm4_mixed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### testing raw distance from median (no abs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "medDistance = DistanceFromMedian()\n",
    "\n",
    "train = np.array(base_loss_values).reshape(len(base_loss_values), 1)\n",
    "conformal_predictor = ConformalAnomalyDetector(ICM=medDistance, x=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "significances = [0.01, 0.05, 0.1, 0.15, 0.25, 0.4, 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## significance: 0.01 ## \n",
      "\n",
      "FP 484\n",
      "TN 49516\n",
      "FN 42627\n",
      "TP 7373\n",
      "accuracy 0.56889\n",
      "\n",
      "\n",
      "## significance: 0.05 ## \n",
      "\n",
      "FP 2498\n",
      "TN 47502\n",
      "FN 31995\n",
      "TP 18005\n",
      "accuracy 0.65507\n",
      "\n",
      "\n",
      "## significance: 0.1 ## \n",
      "\n",
      "FP 4981\n",
      "TN 45019\n",
      "FN 22476\n",
      "TP 27524\n",
      "accuracy 0.72543\n",
      "\n",
      "\n",
      "## significance: 0.15 ## \n",
      "\n",
      "FP 7492\n",
      "TN 42508\n",
      "FN 15514\n",
      "TP 34486\n",
      "accuracy 0.76994\n",
      "\n",
      "\n",
      "## significance: 0.25 ## \n",
      "\n",
      "FP 12479\n",
      "TN 37521\n",
      "FN 8223\n",
      "TP 41777\n",
      "accuracy 0.79298\n",
      "\n",
      "\n",
      "## significance: 0.4 ## \n",
      "\n",
      "FP 19978\n",
      "TN 30022\n",
      "FN 3605\n",
      "TP 46395\n",
      "accuracy 0.76417\n",
      "\n",
      "\n",
      "## significance: 0.5 ## \n",
      "\n",
      "FP 24978\n",
      "TN 25022\n",
      "FN 2045\n",
      "TP 47955\n",
      "accuracy 0.72977\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for s in significances: \n",
    "    conformal_predictor.set_significance(s)\n",
    "    test = np.array(fgsm4_mixed).reshape(len(fgsm4_mixed), 1)\n",
    "    is_outlier = conformal_predictor(test)\n",
    "\n",
    "    print(f\"## significance: {s} ## \\n\")\n",
    "\n",
    "    print(\"FP\", sum(is_outlier[0:len(base_loss_values)]))\n",
    "    print(\"TN\", len(base_loss_values) - sum(is_outlier[0:len(base_loss_values)]))\n",
    "    print(\"FN\", len(fgsm4_clean) - sum(is_outlier[len(base_loss_values):]))\n",
    "    print(\"TP\", sum(is_outlier[len(base_loss_values):]))\n",
    "    print(\"accuracy\", (sum(is_outlier[len(base_loss_values):]) + len(base_loss_values) - sum(is_outlier[0:len(base_loss_values)])) / len(fgsm4_mixed))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PGDl2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"output/base_loss.pkl\", \"rb\") as f:\n",
    "    base_loss_values = pickle.load(f)\\\n",
    "\n",
    "with open(\"output/pgdl2_mixed2.pkl\", \"rb\") as f:\n",
    "    pgdl2_mixed = pickle.load(f)\n",
    "\n",
    "with open(\"output/pgdl2_loss.pkl\", \"rb\") as f:\n",
    "    pgdl2_clean = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "medDistance = DistanceFromMedian()\n",
    "\n",
    "train = np.array(base_loss_values).reshape(len(base_loss_values), 1)\n",
    "conformal_predictor = ConformalAnomalyDetector(ICM=medDistance, x=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "significances = [0.01, 0.05, 0.1, 0.15, 0.25, 0.4, 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## significance: 0.01 ## \n",
      "\n",
      "FP 484\n",
      "TN 49516\n",
      "FN 45913\n",
      "TP 4087\n",
      "accuracy 0.53603\n",
      "\n",
      "\n",
      "## significance: 0.05 ## \n",
      "\n",
      "FP 2498\n",
      "TN 47502\n",
      "FN 40151\n",
      "TP 9849\n",
      "accuracy 0.57351\n",
      "\n",
      "\n",
      "## significance: 0.1 ## \n",
      "\n",
      "FP 4981\n",
      "TN 45019\n",
      "FN 34269\n",
      "TP 15731\n",
      "accuracy 0.6075\n",
      "\n",
      "\n",
      "## significance: 0.15 ## \n",
      "\n",
      "FP 7492\n",
      "TN 42508\n",
      "FN 28655\n",
      "TP 21345\n",
      "accuracy 0.63853\n",
      "\n",
      "\n",
      "## significance: 0.25 ## \n",
      "\n",
      "FP 12479\n",
      "TN 37521\n",
      "FN 20507\n",
      "TP 29493\n",
      "accuracy 0.67014\n",
      "\n",
      "\n",
      "## significance: 0.4 ## \n",
      "\n",
      "FP 19978\n",
      "TN 30022\n",
      "FN 12858\n",
      "TP 37142\n",
      "accuracy 0.67164\n",
      "\n",
      "\n",
      "## significance: 0.5 ## \n",
      "\n",
      "FP 24978\n",
      "TN 25022\n",
      "FN 9322\n",
      "TP 40678\n",
      "accuracy 0.657\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for s in significances: \n",
    "    conformal_predictor.set_significance(s)\n",
    "    test = np.array(pgdl2_mixed).reshape(len(pgdl2_mixed), 1)\n",
    "    is_outlier = conformal_predictor(test)\n",
    "\n",
    "    print(f\"## significance: {s} ## \\n\")\n",
    "\n",
    "    print(\"FP\", sum(is_outlier[0:len(base_loss_values)]))\n",
    "    print(\"TN\", len(base_loss_values) - sum(is_outlier[0:len(base_loss_values)]))\n",
    "    print(\"FN\", len(pgdl2_clean) - sum(is_outlier[len(base_loss_values):]))\n",
    "    print(\"TP\", sum(is_outlier[len(base_loss_values):]))\n",
    "    print(\"accuracy\", (sum(is_outlier[len(base_loss_values):]) + len(base_loss_values) - sum(is_outlier[0:len(base_loss_values)])) / len(pgdl2_mixed))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c09d1698212c735a3443dc0423fe58b563a1b228e762256a81505a70ae1393dc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
