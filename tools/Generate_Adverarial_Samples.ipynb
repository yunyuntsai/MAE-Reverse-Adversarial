{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Albert Wen\\AppData\\Local\\Temp\\ipykernel_14740\\342765283.py:13: DeprecationWarning: `set_matplotlib_formats` is deprecated since IPython 7.23, directly use `matplotlib_inline.backend_inline.set_matplotlib_formats()`\n",
      "  set_matplotlib_formats('svg', 'pdf') # For export\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda:0\n"
     ]
    }
   ],
   "source": [
    "## Standard libraries\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "import scipy.linalg\n",
    "\n",
    "## Imports for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('svg', 'pdf') # For export\n",
    "from matplotlib.colors import to_rgb\n",
    "import matplotlib\n",
    "matplotlib.rcParams['lines.linewidth'] = 2.0\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "## Progress bar\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "## PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim\n",
    "# Torchvision\n",
    "import torchvision\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision import transforms\n",
    "# PyTorch Lightning\n",
    "try:\n",
    "    import pytorch_lightning as pl\n",
    "except ModuleNotFoundError: # Google Colab does not have PyTorch Lightning installed by default. Hence, we do it here if necessary\n",
    "    !pip install --quiet pytorch-lightning>=1.4\n",
    "    import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\n",
    "\n",
    "\n",
    "# Path to the folder where the datasets are/should be downloaded (e.g. MNIST)\n",
    "# DATASET_PATH = \"/local/rcs/yunyun\"\n",
    "DATASET_PATH = \"c:/users/Albert Wen/ml_security\"\n",
    "# Path to the folder where the pretrained models are saved\n",
    "CHECKPOINT_PATH = \"c:/users/Albert Wen/resnet50.pth\"\n",
    "\n",
    "# Setting the seed\n",
    "pl.seed_everything(42)\n",
    "\n",
    "# Ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Fetching the device that will be used throughout this notebook\n",
    "device = torch.device(\"cpu\") if not torch.cuda.is_available() else torch.device(\"cuda:0\")\n",
    "print(\"Using device\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> load chechpoint found at c:/users/Albert Wen/resnet50.pth\n"
     ]
    }
   ],
   "source": [
    "# Load CNN architecture pretrained on ImageNet\n",
    "# os.environ[\"TORCH_HOME\"] = CHECKPOINT_PATH\n",
    "pretrained_model = torchvision.models.resnet50(pretrained=True)\n",
    "pretrained_model = pretrained_model.to(device)\n",
    "\n",
    "if CHECKPOINT_PATH:\n",
    "    if os.path.isfile(CHECKPOINT_PATH):\n",
    "        checkpoint = torch.load(CHECKPOINT_PATH) \n",
    "        # model.load_state_dict(checkpoint['state_dict'])  #['state_dict']\n",
    "        pretrained_model.load_state_dict(checkpoint)  #['state_dict']\n",
    "        print(\"=> load chechpoint found at {}\".format(CHECKPOINT_PATH))\n",
    "        # print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "        #       .format(args.resume, checkpoint['epoch']))\n",
    "    else:\n",
    "        print(\"=> no checkpoint found at '{}'\".format(CHECKPOINT_PATH))\n",
    "# No gradients needed for the network\n",
    "pretrained_model.eval()\n",
    "for p in pretrained_model.parameters():\n",
    "    p.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5           [-1, 64, 56, 56]           4,096\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "              ReLU-7           [-1, 64, 56, 56]               0\n",
      "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
      "             ReLU-10           [-1, 64, 56, 56]               0\n",
      "           Conv2d-11          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-12          [-1, 256, 56, 56]             512\n",
      "           Conv2d-13          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-14          [-1, 256, 56, 56]             512\n",
      "             ReLU-15          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-16          [-1, 256, 56, 56]               0\n",
      "           Conv2d-17           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-18           [-1, 64, 56, 56]             128\n",
      "             ReLU-19           [-1, 64, 56, 56]               0\n",
      "           Conv2d-20           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-21           [-1, 64, 56, 56]             128\n",
      "             ReLU-22           [-1, 64, 56, 56]               0\n",
      "           Conv2d-23          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-24          [-1, 256, 56, 56]             512\n",
      "             ReLU-25          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-26          [-1, 256, 56, 56]               0\n",
      "           Conv2d-27           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-28           [-1, 64, 56, 56]             128\n",
      "             ReLU-29           [-1, 64, 56, 56]               0\n",
      "           Conv2d-30           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-31           [-1, 64, 56, 56]             128\n",
      "             ReLU-32           [-1, 64, 56, 56]               0\n",
      "           Conv2d-33          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-34          [-1, 256, 56, 56]             512\n",
      "             ReLU-35          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-36          [-1, 256, 56, 56]               0\n",
      "           Conv2d-37          [-1, 128, 56, 56]          32,768\n",
      "      BatchNorm2d-38          [-1, 128, 56, 56]             256\n",
      "             ReLU-39          [-1, 128, 56, 56]               0\n",
      "           Conv2d-40          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-41          [-1, 128, 28, 28]             256\n",
      "             ReLU-42          [-1, 128, 28, 28]               0\n",
      "           Conv2d-43          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-44          [-1, 512, 28, 28]           1,024\n",
      "           Conv2d-45          [-1, 512, 28, 28]         131,072\n",
      "      BatchNorm2d-46          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-47          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-48          [-1, 512, 28, 28]               0\n",
      "           Conv2d-49          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-50          [-1, 128, 28, 28]             256\n",
      "             ReLU-51          [-1, 128, 28, 28]               0\n",
      "           Conv2d-52          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-53          [-1, 128, 28, 28]             256\n",
      "             ReLU-54          [-1, 128, 28, 28]               0\n",
      "           Conv2d-55          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-56          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-57          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-58          [-1, 512, 28, 28]               0\n",
      "           Conv2d-59          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-60          [-1, 128, 28, 28]             256\n",
      "             ReLU-61          [-1, 128, 28, 28]               0\n",
      "           Conv2d-62          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-63          [-1, 128, 28, 28]             256\n",
      "             ReLU-64          [-1, 128, 28, 28]               0\n",
      "           Conv2d-65          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-66          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-67          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-68          [-1, 512, 28, 28]               0\n",
      "           Conv2d-69          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-70          [-1, 128, 28, 28]             256\n",
      "             ReLU-71          [-1, 128, 28, 28]               0\n",
      "           Conv2d-72          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-73          [-1, 128, 28, 28]             256\n",
      "             ReLU-74          [-1, 128, 28, 28]               0\n",
      "           Conv2d-75          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-76          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-77          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-78          [-1, 512, 28, 28]               0\n",
      "           Conv2d-79          [-1, 256, 28, 28]         131,072\n",
      "      BatchNorm2d-80          [-1, 256, 28, 28]             512\n",
      "             ReLU-81          [-1, 256, 28, 28]               0\n",
      "           Conv2d-82          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-83          [-1, 256, 14, 14]             512\n",
      "             ReLU-84          [-1, 256, 14, 14]               0\n",
      "           Conv2d-85         [-1, 1024, 14, 14]         262,144\n",
      "      BatchNorm2d-86         [-1, 1024, 14, 14]           2,048\n",
      "           Conv2d-87         [-1, 1024, 14, 14]         524,288\n",
      "      BatchNorm2d-88         [-1, 1024, 14, 14]           2,048\n",
      "             ReLU-89         [-1, 1024, 14, 14]               0\n",
      "       Bottleneck-90         [-1, 1024, 14, 14]               0\n",
      "           Conv2d-91          [-1, 256, 14, 14]         262,144\n",
      "      BatchNorm2d-92          [-1, 256, 14, 14]             512\n",
      "             ReLU-93          [-1, 256, 14, 14]               0\n",
      "           Conv2d-94          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-95          [-1, 256, 14, 14]             512\n",
      "             ReLU-96          [-1, 256, 14, 14]               0\n",
      "           Conv2d-97         [-1, 1024, 14, 14]         262,144\n",
      "      BatchNorm2d-98         [-1, 1024, 14, 14]           2,048\n",
      "             ReLU-99         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-100         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-101          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-102          [-1, 256, 14, 14]             512\n",
      "            ReLU-103          [-1, 256, 14, 14]               0\n",
      "          Conv2d-104          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-105          [-1, 256, 14, 14]             512\n",
      "            ReLU-106          [-1, 256, 14, 14]               0\n",
      "          Conv2d-107         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-108         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-109         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-110         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-111          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-112          [-1, 256, 14, 14]             512\n",
      "            ReLU-113          [-1, 256, 14, 14]               0\n",
      "          Conv2d-114          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-115          [-1, 256, 14, 14]             512\n",
      "            ReLU-116          [-1, 256, 14, 14]               0\n",
      "          Conv2d-117         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-118         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-119         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-120         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-121          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-122          [-1, 256, 14, 14]             512\n",
      "            ReLU-123          [-1, 256, 14, 14]               0\n",
      "          Conv2d-124          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-125          [-1, 256, 14, 14]             512\n",
      "            ReLU-126          [-1, 256, 14, 14]               0\n",
      "          Conv2d-127         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-129         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-130         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-131          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-132          [-1, 256, 14, 14]             512\n",
      "            ReLU-133          [-1, 256, 14, 14]               0\n",
      "          Conv2d-134          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-135          [-1, 256, 14, 14]             512\n",
      "            ReLU-136          [-1, 256, 14, 14]               0\n",
      "          Conv2d-137         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-138         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-139         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-140         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-141          [-1, 512, 14, 14]         524,288\n",
      "     BatchNorm2d-142          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-143          [-1, 512, 14, 14]               0\n",
      "          Conv2d-144            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-145            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-146            [-1, 512, 7, 7]               0\n",
      "          Conv2d-147           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-148           [-1, 2048, 7, 7]           4,096\n",
      "          Conv2d-149           [-1, 2048, 7, 7]       2,097,152\n",
      "     BatchNorm2d-150           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-151           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-152           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-153            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-154            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-155            [-1, 512, 7, 7]               0\n",
      "          Conv2d-156            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-157            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-158            [-1, 512, 7, 7]               0\n",
      "          Conv2d-159           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-160           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-161           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-162           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-163            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-164            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-165            [-1, 512, 7, 7]               0\n",
      "          Conv2d-166            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-167            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-168            [-1, 512, 7, 7]               0\n",
      "          Conv2d-169           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-170           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-171           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-172           [-1, 2048, 7, 7]               0\n",
      "AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n",
      "          Linear-174                 [-1, 1000]       2,049,000\n",
      "================================================================\n",
      "Total params: 25,557,032\n",
      "Trainable params: 0\n",
      "Non-trainable params: 25,557,032\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 286.56\n",
      "Params size (MB): 97.49\n",
      "Estimated Total Size (MB): 384.62\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(pretrained_model, (3,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean and Std from ImageNet\n",
    "# NORM_MEAN = np.array([0.485, 0.456, 0.406])\n",
    "# NORM_STD = np.array([0.229, 0.224, 0.225])\n",
    "from timm.data.constants import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD\n",
    "# No resizing and center crop necessary as images are already preprocessed.\n",
    "plain_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize(256), transforms.CenterCrop(224),\n",
    "#     transforms.Normalize(IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.datasets as dsets  \n",
    "def image_folder_custom_label(root, transform, idx2label) :\n",
    "    \n",
    "    # custom_label\n",
    "    # type : List\n",
    "    # index -> label\n",
    "    # ex) ['tench', 'goldfish', 'great_white_shark', 'tiger_shark']\n",
    "    \n",
    "    old_data = dsets.ImageFolder(root=root, transform=transform)\n",
    "    old_classes = old_data.classes\n",
    "    \n",
    "    label2idx = {}\n",
    "    \n",
    "    for i, item in enumerate(idx2label) :\n",
    " \n",
    "        label2idx[item] = old_classes[i]\n",
    "    \n",
    "    key_list = list(label2idx.keys())\n",
    "    val_list = list(label2idx.values())\n",
    "    \n",
    "    new_data = dsets.ImageFolder(root=root, transform=transform, \n",
    "                                 target_transform=lambda x :  key_list[val_list.index(old_classes[x])])\n",
    "    new_data.classes = idx2label\n",
    "    new_data.class_to_idx = label2idx\n",
    "\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json\n",
    "class_idx = json.load(open(\"./imagenet_class_index.json\"))\n",
    "idx2label = [class_idx[str(k)][1] for k in range(len(class_idx))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import imshow\n",
    "# Load dataset and create data loader\n",
    "imagenet_path = os.path.join(DATASET_PATH, \"ImageNet-Data\")\n",
    "assert os.path.isdir(imagenet_path), f\"Could not find the ImageNet dataset at expected path \\\"{imagenet_path}\\\". \" + \\\n",
    "                                     f\"Please make sure to have downloaded the ImageNet dataset here, or change the {DATASET_PATH=} variable.\"\n",
    "\n",
    "val_dataset = torchvision.datasets.ImageFolder(root=os.path.join(imagenet_path, 'val'), transform=plain_transforms)\n",
    "val_dataset_loader = data.DataLoader(val_dataset, batch_size=32, shuffle=False, drop_last=False, num_workers=5)\n",
    "\n",
    "imagenet_data = image_folder_custom_label(root=os.path.join(imagenet_path, 'val'), transform=plain_transforms, idx2label=idx2label)\n",
    "data_loader = torch.utils.data.DataLoader(imagenet_data, batch_size=32, shuffle=False)\n",
    "\n",
    "# print(np.unique(val_dataset.targets))\n",
    "# # Load label names to interpret the label numbers 0 to 999\n",
    "# with open(os.path.join(imagenet_path, \"label_list.json\"), \"r\") as f:\n",
    "#     label_names = json.load(f)\n",
    "\n",
    "# def get_label_index(lab_str):\n",
    "#     assert lab_str in label_names, f\"Label \\\"{lab_str}\\\" not found. Check the spelling of the class.\"\n",
    "#     return label_names.index(lab_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images, labels = iter(data_loader).next()\n",
    "# print(images.shape)\n",
    "# print(\"True Image & True Label\")\n",
    "# imshow(torchvision.utils.make_grid(images, normalize=True), labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(dataset_loader, img_func=None):\n",
    "    tp, tp_5, counter = 0., 0., 0.\n",
    "    for imgs, labels in tqdm(dataset_loader, desc=\"Validating...\"):\n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        if img_func is not None:\n",
    "            imgs = img_func(imgs, labels)\n",
    "        with torch.no_grad():\n",
    "            preds = pretrained_model(imgs)\n",
    "        tp += (preds.argmax(dim=-1) == labels).sum()\n",
    "        tp_5 += (preds.topk(5, dim=-1)[1] == labels[...,None]).any(dim=-1).sum()\n",
    "        counter += preds.shape[0]\n",
    "    acc = tp.float().item()/counter\n",
    "    top5 = tp_5.float().item()/counter\n",
    "    print(f\"Top-1 acc: {(100.0 * (acc)):4.2f}%\")\n",
    "    print(f\"Top-5 acc: {(100.0 * (top5)):4.2f}%\")\n",
    "    return acc, top5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e51db30741bd49cf8058103c4278bd59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating...:   0%|          | 0/1563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 acc: 54.57%\n",
      "Top-5 acc: 79.34%\n"
     ]
    }
   ],
   "source": [
    "_ = eval_model(val_dataset_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchattacks import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "atks = [\n",
    "    # FGSM(pretrained_model, eps=4/255)\n",
    "#     FGSM(pretrained_model, eps=8/255),\n",
    "    FGSM(pretrained_model, eps=16/255),\n",
    "#     BIM(pretrained_model, eps=8/255, alpha=2/255, steps=10),\n",
    "#     RFGSM(pretrained_model, eps=8/255, alpha=2/255, steps=100),\n",
    "#     CW(pretrained_model, c=1, lr=0.01, steps=10, kappa=0),\n",
    "#     PGD(pretrained_model, eps=8/255, alpha=2/225, steps=10,random_start=False)\n",
    "#     PGDL2(pretrained_model, eps=1, alpha=0.2, steps=10)\n",
    "#     EOTPGD(pretrained_model, eps=8/255, alpha=2/255, steps=100, eot_iter=2),\n",
    "#     FFGSM(pretrained_model, eps=8/255, alpha=10/255),\n",
    "#     TPGD(pretrained_model, eps=8/255, alpha=2/255, steps=100),\n",
    "#     MIFGSM(pretrained_model, eps=8/255, alpha=2/255, steps=100, decay=0.1),\n",
    "#     VANILA(pretrained_model),\n",
    "#     GN(pretrained_model, std=0.1),\n",
    "#     APGD(pretrained_model, eps=8/255, steps=100, eot_iter=1, n_restarts=1, loss='ce'),\n",
    "#     APGD(pretrained_model, eps=8/255, steps=10, eot_iter=1, n_restarts=1, loss='dlr'),\n",
    "#     APGDT(pretrained_model, eps=8/255, steps=100, eot_iter=1, n_restarts=1),\n",
    "#     FAB(pretrained_model, eps=8/255, steps=100, n_classes=10, n_restarts=1, targeted=False),\n",
    "#     FAB(pretrained_model, eps=8/255, steps=100, n_classes=10, n_restarts=1, targeted=True),\n",
    "#     Square(pretrained_model, eps=8/255, n_queries=5000, n_restarts=1, loss='ce'),\n",
    "#     AutoAttack(pretrained_model, eps=8/255, n_classes=10, version='standard'),\n",
    "#     OnePixel(pretrained_model, pixels=5, steps=10, inf_batch=50),\n",
    "#     DeepFool(pretrained_model, steps=10),\n",
    "#     DIFGSM(pretrained_model, eps=8/255, alpha=2/255, steps=100, diversity_prob=0.5, resize_rate=0.9)\n",
    "#       Pixle(pretrained_model, x_dimensions=(0.1, 0.2), restarts=10, max_iterations=10)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     FGSM(pretrained_model, eps=8/255),\n",
    "#     FGSM(pretrained_model, eps=16/255),\n",
    "#     BIM(pretrained_model, eps=8/255, alpha=2/255, steps=10),\n",
    "#     CW(pretrained_model, c=1, lr=0.01, steps=10, kappa=0),\n",
    "#     PGD(pretrained_model, eps=8/255, alpha=2/225, steps=10, random_start=True)\n",
    "#     PGD(pretrained_model, eps=16/255, alpha=2/225, steps=10, random_start=True)\n",
    "#     PGDL2(pretrained_model, eps=1, alpha=0.2, steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tench',\n",
       " 'goldfish',\n",
       " 'great_white_shark',\n",
       " 'tiger_shark',\n",
       " 'hammerhead',\n",
       " 'electric_ray',\n",
       " 'stingray',\n",
       " 'cock',\n",
       " 'hen',\n",
       " 'ostrich',\n",
       " 'brambling',\n",
       " 'goldfinch',\n",
       " 'house_finch',\n",
       " 'junco',\n",
       " 'indigo_bunting',\n",
       " 'robin',\n",
       " 'bulbul',\n",
       " 'jay',\n",
       " 'magpie',\n",
       " 'chickadee',\n",
       " 'water_ouzel',\n",
       " 'kite',\n",
       " 'bald_eagle',\n",
       " 'vulture',\n",
       " 'great_grey_owl',\n",
       " 'European_fire_salamander',\n",
       " 'common_newt',\n",
       " 'eft',\n",
       " 'spotted_salamander',\n",
       " 'axolotl',\n",
       " 'bullfrog',\n",
       " 'tree_frog',\n",
       " 'tailed_frog',\n",
       " 'loggerhead',\n",
       " 'leatherback_turtle',\n",
       " 'mud_turtle',\n",
       " 'terrapin',\n",
       " 'box_turtle',\n",
       " 'banded_gecko',\n",
       " 'common_iguana',\n",
       " 'American_chameleon',\n",
       " 'whiptail',\n",
       " 'agama',\n",
       " 'frilled_lizard',\n",
       " 'alligator_lizard',\n",
       " 'Gila_monster',\n",
       " 'green_lizard',\n",
       " 'African_chameleon',\n",
       " 'Komodo_dragon',\n",
       " 'African_crocodile',\n",
       " 'American_alligator',\n",
       " 'triceratops',\n",
       " 'thunder_snake',\n",
       " 'ringneck_snake',\n",
       " 'hognose_snake',\n",
       " 'green_snake',\n",
       " 'king_snake',\n",
       " 'garter_snake',\n",
       " 'water_snake',\n",
       " 'vine_snake',\n",
       " 'night_snake',\n",
       " 'boa_constrictor',\n",
       " 'rock_python',\n",
       " 'Indian_cobra',\n",
       " 'green_mamba',\n",
       " 'sea_snake',\n",
       " 'horned_viper',\n",
       " 'diamondback',\n",
       " 'sidewinder',\n",
       " 'trilobite',\n",
       " 'harvestman',\n",
       " 'scorpion',\n",
       " 'black_and_gold_garden_spider',\n",
       " 'barn_spider',\n",
       " 'garden_spider',\n",
       " 'black_widow',\n",
       " 'tarantula',\n",
       " 'wolf_spider',\n",
       " 'tick',\n",
       " 'centipede',\n",
       " 'black_grouse',\n",
       " 'ptarmigan',\n",
       " 'ruffed_grouse',\n",
       " 'prairie_chicken',\n",
       " 'peacock',\n",
       " 'quail',\n",
       " 'partridge',\n",
       " 'African_grey',\n",
       " 'macaw',\n",
       " 'sulphur-crested_cockatoo',\n",
       " 'lorikeet',\n",
       " 'coucal',\n",
       " 'bee_eater',\n",
       " 'hornbill',\n",
       " 'hummingbird',\n",
       " 'jacamar',\n",
       " 'toucan',\n",
       " 'drake',\n",
       " 'red-breasted_merganser',\n",
       " 'goose',\n",
       " 'black_swan',\n",
       " 'tusker',\n",
       " 'echidna',\n",
       " 'platypus',\n",
       " 'wallaby',\n",
       " 'koala',\n",
       " 'wombat',\n",
       " 'jellyfish',\n",
       " 'sea_anemone',\n",
       " 'brain_coral',\n",
       " 'flatworm',\n",
       " 'nematode',\n",
       " 'conch',\n",
       " 'snail',\n",
       " 'slug',\n",
       " 'sea_slug',\n",
       " 'chiton',\n",
       " 'chambered_nautilus',\n",
       " 'Dungeness_crab',\n",
       " 'rock_crab',\n",
       " 'fiddler_crab',\n",
       " 'king_crab',\n",
       " 'American_lobster',\n",
       " 'spiny_lobster',\n",
       " 'crayfish',\n",
       " 'hermit_crab',\n",
       " 'isopod',\n",
       " 'white_stork',\n",
       " 'black_stork',\n",
       " 'spoonbill',\n",
       " 'flamingo',\n",
       " 'little_blue_heron',\n",
       " 'American_egret',\n",
       " 'bittern',\n",
       " 'crane',\n",
       " 'limpkin',\n",
       " 'European_gallinule',\n",
       " 'American_coot',\n",
       " 'bustard',\n",
       " 'ruddy_turnstone',\n",
       " 'red-backed_sandpiper',\n",
       " 'redshank',\n",
       " 'dowitcher',\n",
       " 'oystercatcher',\n",
       " 'pelican',\n",
       " 'king_penguin',\n",
       " 'albatross',\n",
       " 'grey_whale',\n",
       " 'killer_whale',\n",
       " 'dugong',\n",
       " 'sea_lion',\n",
       " 'Chihuahua',\n",
       " 'Japanese_spaniel',\n",
       " 'Maltese_dog',\n",
       " 'Pekinese',\n",
       " 'Shih-Tzu',\n",
       " 'Blenheim_spaniel',\n",
       " 'papillon',\n",
       " 'toy_terrier',\n",
       " 'Rhodesian_ridgeback',\n",
       " 'Afghan_hound',\n",
       " 'basset',\n",
       " 'beagle',\n",
       " 'bloodhound',\n",
       " 'bluetick',\n",
       " 'black-and-tan_coonhound',\n",
       " 'Walker_hound',\n",
       " 'English_foxhound',\n",
       " 'redbone',\n",
       " 'borzoi',\n",
       " 'Irish_wolfhound',\n",
       " 'Italian_greyhound',\n",
       " 'whippet',\n",
       " 'Ibizan_hound',\n",
       " 'Norwegian_elkhound',\n",
       " 'otterhound',\n",
       " 'Saluki',\n",
       " 'Scottish_deerhound',\n",
       " 'Weimaraner',\n",
       " 'Staffordshire_bullterrier',\n",
       " 'American_Staffordshire_terrier',\n",
       " 'Bedlington_terrier',\n",
       " 'Border_terrier',\n",
       " 'Kerry_blue_terrier',\n",
       " 'Irish_terrier',\n",
       " 'Norfolk_terrier',\n",
       " 'Norwich_terrier',\n",
       " 'Yorkshire_terrier',\n",
       " 'wire-haired_fox_terrier',\n",
       " 'Lakeland_terrier',\n",
       " 'Sealyham_terrier',\n",
       " 'Airedale',\n",
       " 'cairn',\n",
       " 'Australian_terrier',\n",
       " 'Dandie_Dinmont',\n",
       " 'Boston_bull',\n",
       " 'miniature_schnauzer',\n",
       " 'giant_schnauzer',\n",
       " 'standard_schnauzer',\n",
       " 'Scotch_terrier',\n",
       " 'Tibetan_terrier',\n",
       " 'silky_terrier',\n",
       " 'soft-coated_wheaten_terrier',\n",
       " 'West_Highland_white_terrier',\n",
       " 'Lhasa',\n",
       " 'flat-coated_retriever',\n",
       " 'curly-coated_retriever',\n",
       " 'golden_retriever',\n",
       " 'Labrador_retriever',\n",
       " 'Chesapeake_Bay_retriever',\n",
       " 'German_short-haired_pointer',\n",
       " 'vizsla',\n",
       " 'English_setter',\n",
       " 'Irish_setter',\n",
       " 'Gordon_setter',\n",
       " 'Brittany_spaniel',\n",
       " 'clumber',\n",
       " 'English_springer',\n",
       " 'Welsh_springer_spaniel',\n",
       " 'cocker_spaniel',\n",
       " 'Sussex_spaniel',\n",
       " 'Irish_water_spaniel',\n",
       " 'kuvasz',\n",
       " 'schipperke',\n",
       " 'groenendael',\n",
       " 'malinois',\n",
       " 'briard',\n",
       " 'kelpie',\n",
       " 'komondor',\n",
       " 'Old_English_sheepdog',\n",
       " 'Shetland_sheepdog',\n",
       " 'collie',\n",
       " 'Border_collie',\n",
       " 'Bouvier_des_Flandres',\n",
       " 'Rottweiler',\n",
       " 'German_shepherd',\n",
       " 'Doberman',\n",
       " 'miniature_pinscher',\n",
       " 'Greater_Swiss_Mountain_dog',\n",
       " 'Bernese_mountain_dog',\n",
       " 'Appenzeller',\n",
       " 'EntleBucher',\n",
       " 'boxer',\n",
       " 'bull_mastiff',\n",
       " 'Tibetan_mastiff',\n",
       " 'French_bulldog',\n",
       " 'Great_Dane',\n",
       " 'Saint_Bernard',\n",
       " 'Eskimo_dog',\n",
       " 'malamute',\n",
       " 'Siberian_husky',\n",
       " 'dalmatian',\n",
       " 'affenpinscher',\n",
       " 'basenji',\n",
       " 'pug',\n",
       " 'Leonberg',\n",
       " 'Newfoundland',\n",
       " 'Great_Pyrenees',\n",
       " 'Samoyed',\n",
       " 'Pomeranian',\n",
       " 'chow',\n",
       " 'keeshond',\n",
       " 'Brabancon_griffon',\n",
       " 'Pembroke',\n",
       " 'Cardigan',\n",
       " 'toy_poodle',\n",
       " 'miniature_poodle',\n",
       " 'standard_poodle',\n",
       " 'Mexican_hairless',\n",
       " 'timber_wolf',\n",
       " 'white_wolf',\n",
       " 'red_wolf',\n",
       " 'coyote',\n",
       " 'dingo',\n",
       " 'dhole',\n",
       " 'African_hunting_dog',\n",
       " 'hyena',\n",
       " 'red_fox',\n",
       " 'kit_fox',\n",
       " 'Arctic_fox',\n",
       " 'grey_fox',\n",
       " 'tabby',\n",
       " 'tiger_cat',\n",
       " 'Persian_cat',\n",
       " 'Siamese_cat',\n",
       " 'Egyptian_cat',\n",
       " 'cougar',\n",
       " 'lynx',\n",
       " 'leopard',\n",
       " 'snow_leopard',\n",
       " 'jaguar',\n",
       " 'lion',\n",
       " 'tiger',\n",
       " 'cheetah',\n",
       " 'brown_bear',\n",
       " 'American_black_bear',\n",
       " 'ice_bear',\n",
       " 'sloth_bear',\n",
       " 'mongoose',\n",
       " 'meerkat',\n",
       " 'tiger_beetle',\n",
       " 'ladybug',\n",
       " 'ground_beetle',\n",
       " 'long-horned_beetle',\n",
       " 'leaf_beetle',\n",
       " 'dung_beetle',\n",
       " 'rhinoceros_beetle',\n",
       " 'weevil',\n",
       " 'fly',\n",
       " 'bee',\n",
       " 'ant',\n",
       " 'grasshopper',\n",
       " 'cricket',\n",
       " 'walking_stick',\n",
       " 'cockroach',\n",
       " 'mantis',\n",
       " 'cicada',\n",
       " 'leafhopper',\n",
       " 'lacewing',\n",
       " 'dragonfly',\n",
       " 'damselfly',\n",
       " 'admiral',\n",
       " 'ringlet',\n",
       " 'monarch',\n",
       " 'cabbage_butterfly',\n",
       " 'sulphur_butterfly',\n",
       " 'lycaenid',\n",
       " 'starfish',\n",
       " 'sea_urchin',\n",
       " 'sea_cucumber',\n",
       " 'wood_rabbit',\n",
       " 'hare',\n",
       " 'Angora',\n",
       " 'hamster',\n",
       " 'porcupine',\n",
       " 'fox_squirrel',\n",
       " 'marmot',\n",
       " 'beaver',\n",
       " 'guinea_pig',\n",
       " 'sorrel',\n",
       " 'zebra',\n",
       " 'hog',\n",
       " 'wild_boar',\n",
       " 'warthog',\n",
       " 'hippopotamus',\n",
       " 'ox',\n",
       " 'water_buffalo',\n",
       " 'bison',\n",
       " 'ram',\n",
       " 'bighorn',\n",
       " 'ibex',\n",
       " 'hartebeest',\n",
       " 'impala',\n",
       " 'gazelle',\n",
       " 'Arabian_camel',\n",
       " 'llama',\n",
       " 'weasel',\n",
       " 'mink',\n",
       " 'polecat',\n",
       " 'black-footed_ferret',\n",
       " 'otter',\n",
       " 'skunk',\n",
       " 'badger',\n",
       " 'armadillo',\n",
       " 'three-toed_sloth',\n",
       " 'orangutan',\n",
       " 'gorilla',\n",
       " 'chimpanzee',\n",
       " 'gibbon',\n",
       " 'siamang',\n",
       " 'guenon',\n",
       " 'patas',\n",
       " 'baboon',\n",
       " 'macaque',\n",
       " 'langur',\n",
       " 'colobus',\n",
       " 'proboscis_monkey',\n",
       " 'marmoset',\n",
       " 'capuchin',\n",
       " 'howler_monkey',\n",
       " 'titi',\n",
       " 'spider_monkey',\n",
       " 'squirrel_monkey',\n",
       " 'Madagascar_cat',\n",
       " 'indri',\n",
       " 'Indian_elephant',\n",
       " 'African_elephant',\n",
       " 'lesser_panda',\n",
       " 'giant_panda',\n",
       " 'barracouta',\n",
       " 'eel',\n",
       " 'coho',\n",
       " 'rock_beauty',\n",
       " 'anemone_fish',\n",
       " 'sturgeon',\n",
       " 'gar',\n",
       " 'lionfish',\n",
       " 'puffer',\n",
       " 'abacus',\n",
       " 'abaya',\n",
       " 'academic_gown',\n",
       " 'accordion',\n",
       " 'acoustic_guitar',\n",
       " 'aircraft_carrier',\n",
       " 'airliner',\n",
       " 'airship',\n",
       " 'altar',\n",
       " 'ambulance',\n",
       " 'amphibian',\n",
       " 'analog_clock',\n",
       " 'apiary',\n",
       " 'apron',\n",
       " 'ashcan',\n",
       " 'assault_rifle',\n",
       " 'backpack',\n",
       " 'bakery',\n",
       " 'balance_beam',\n",
       " 'balloon',\n",
       " 'ballpoint',\n",
       " 'Band_Aid',\n",
       " 'banjo',\n",
       " 'bannister',\n",
       " 'barbell',\n",
       " 'barber_chair',\n",
       " 'barbershop',\n",
       " 'barn',\n",
       " 'barometer',\n",
       " 'barrel',\n",
       " 'barrow',\n",
       " 'baseball',\n",
       " 'basketball',\n",
       " 'bassinet',\n",
       " 'bassoon',\n",
       " 'bathing_cap',\n",
       " 'bath_towel',\n",
       " 'bathtub',\n",
       " 'beach_wagon',\n",
       " 'beacon',\n",
       " 'beaker',\n",
       " 'bearskin',\n",
       " 'beer_bottle',\n",
       " 'beer_glass',\n",
       " 'bell_cote',\n",
       " 'bib',\n",
       " 'bicycle-built-for-two',\n",
       " 'bikini',\n",
       " 'binder',\n",
       " 'binoculars',\n",
       " 'birdhouse',\n",
       " 'boathouse',\n",
       " 'bobsled',\n",
       " 'bolo_tie',\n",
       " 'bonnet',\n",
       " 'bookcase',\n",
       " 'bookshop',\n",
       " 'bottlecap',\n",
       " 'bow',\n",
       " 'bow_tie',\n",
       " 'brass',\n",
       " 'brassiere',\n",
       " 'breakwater',\n",
       " 'breastplate',\n",
       " 'broom',\n",
       " 'bucket',\n",
       " 'buckle',\n",
       " 'bulletproof_vest',\n",
       " 'bullet_train',\n",
       " 'butcher_shop',\n",
       " 'cab',\n",
       " 'caldron',\n",
       " 'candle',\n",
       " 'cannon',\n",
       " 'canoe',\n",
       " 'can_opener',\n",
       " 'cardigan',\n",
       " 'car_mirror',\n",
       " 'carousel',\n",
       " \"carpenter's_kit\",\n",
       " 'carton',\n",
       " 'car_wheel',\n",
       " 'cash_machine',\n",
       " 'cassette',\n",
       " 'cassette_player',\n",
       " 'castle',\n",
       " 'catamaran',\n",
       " 'CD_player',\n",
       " 'cello',\n",
       " 'cellular_telephone',\n",
       " 'chain',\n",
       " 'chainlink_fence',\n",
       " 'chain_mail',\n",
       " 'chain_saw',\n",
       " 'chest',\n",
       " 'chiffonier',\n",
       " 'chime',\n",
       " 'china_cabinet',\n",
       " 'Christmas_stocking',\n",
       " 'church',\n",
       " 'cinema',\n",
       " 'cleaver',\n",
       " 'cliff_dwelling',\n",
       " 'cloak',\n",
       " 'clog',\n",
       " 'cocktail_shaker',\n",
       " 'coffee_mug',\n",
       " 'coffeepot',\n",
       " 'coil',\n",
       " 'combination_lock',\n",
       " 'computer_keyboard',\n",
       " 'confectionery',\n",
       " 'container_ship',\n",
       " 'convertible',\n",
       " 'corkscrew',\n",
       " 'cornet',\n",
       " 'cowboy_boot',\n",
       " 'cowboy_hat',\n",
       " 'cradle',\n",
       " 'crane',\n",
       " 'crash_helmet',\n",
       " 'crate',\n",
       " 'crib',\n",
       " 'Crock_Pot',\n",
       " 'croquet_ball',\n",
       " 'crutch',\n",
       " 'cuirass',\n",
       " 'dam',\n",
       " 'desk',\n",
       " 'desktop_computer',\n",
       " 'dial_telephone',\n",
       " 'diaper',\n",
       " 'digital_clock',\n",
       " 'digital_watch',\n",
       " 'dining_table',\n",
       " 'dishrag',\n",
       " 'dishwasher',\n",
       " 'disk_brake',\n",
       " 'dock',\n",
       " 'dogsled',\n",
       " 'dome',\n",
       " 'doormat',\n",
       " 'drilling_platform',\n",
       " 'drum',\n",
       " 'drumstick',\n",
       " 'dumbbell',\n",
       " 'Dutch_oven',\n",
       " 'electric_fan',\n",
       " 'electric_guitar',\n",
       " 'electric_locomotive',\n",
       " 'entertainment_center',\n",
       " 'envelope',\n",
       " 'espresso_maker',\n",
       " 'face_powder',\n",
       " 'feather_boa',\n",
       " 'file',\n",
       " 'fireboat',\n",
       " 'fire_engine',\n",
       " 'fire_screen',\n",
       " 'flagpole',\n",
       " 'flute',\n",
       " 'folding_chair',\n",
       " 'football_helmet',\n",
       " 'forklift',\n",
       " 'fountain',\n",
       " 'fountain_pen',\n",
       " 'four-poster',\n",
       " 'freight_car',\n",
       " 'French_horn',\n",
       " 'frying_pan',\n",
       " 'fur_coat',\n",
       " 'garbage_truck',\n",
       " 'gasmask',\n",
       " 'gas_pump',\n",
       " 'goblet',\n",
       " 'go-kart',\n",
       " 'golf_ball',\n",
       " 'golfcart',\n",
       " 'gondola',\n",
       " 'gong',\n",
       " 'gown',\n",
       " 'grand_piano',\n",
       " 'greenhouse',\n",
       " 'grille',\n",
       " 'grocery_store',\n",
       " 'guillotine',\n",
       " 'hair_slide',\n",
       " 'hair_spray',\n",
       " 'half_track',\n",
       " 'hammer',\n",
       " 'hamper',\n",
       " 'hand_blower',\n",
       " 'hand-held_computer',\n",
       " 'handkerchief',\n",
       " 'hard_disc',\n",
       " 'harmonica',\n",
       " 'harp',\n",
       " 'harvester',\n",
       " 'hatchet',\n",
       " 'holster',\n",
       " 'home_theater',\n",
       " 'honeycomb',\n",
       " 'hook',\n",
       " 'hoopskirt',\n",
       " 'horizontal_bar',\n",
       " 'horse_cart',\n",
       " 'hourglass',\n",
       " 'iPod',\n",
       " 'iron',\n",
       " \"jack-o'-lantern\",\n",
       " 'jean',\n",
       " 'jeep',\n",
       " 'jersey',\n",
       " 'jigsaw_puzzle',\n",
       " 'jinrikisha',\n",
       " 'joystick',\n",
       " 'kimono',\n",
       " 'knee_pad',\n",
       " 'knot',\n",
       " 'lab_coat',\n",
       " 'ladle',\n",
       " 'lampshade',\n",
       " 'laptop',\n",
       " 'lawn_mower',\n",
       " 'lens_cap',\n",
       " 'letter_opener',\n",
       " 'library',\n",
       " 'lifeboat',\n",
       " 'lighter',\n",
       " 'limousine',\n",
       " 'liner',\n",
       " 'lipstick',\n",
       " 'Loafer',\n",
       " 'lotion',\n",
       " 'loudspeaker',\n",
       " 'loupe',\n",
       " 'lumbermill',\n",
       " 'magnetic_compass',\n",
       " 'mailbag',\n",
       " 'mailbox',\n",
       " 'maillot',\n",
       " 'maillot',\n",
       " 'manhole_cover',\n",
       " 'maraca',\n",
       " 'marimba',\n",
       " 'mask',\n",
       " 'matchstick',\n",
       " 'maypole',\n",
       " 'maze',\n",
       " 'measuring_cup',\n",
       " 'medicine_chest',\n",
       " 'megalith',\n",
       " 'microphone',\n",
       " 'microwave',\n",
       " 'military_uniform',\n",
       " 'milk_can',\n",
       " 'minibus',\n",
       " 'miniskirt',\n",
       " 'minivan',\n",
       " 'missile',\n",
       " 'mitten',\n",
       " 'mixing_bowl',\n",
       " 'mobile_home',\n",
       " 'Model_T',\n",
       " 'modem',\n",
       " 'monastery',\n",
       " 'monitor',\n",
       " 'moped',\n",
       " 'mortar',\n",
       " 'mortarboard',\n",
       " 'mosque',\n",
       " 'mosquito_net',\n",
       " 'motor_scooter',\n",
       " 'mountain_bike',\n",
       " 'mountain_tent',\n",
       " 'mouse',\n",
       " 'mousetrap',\n",
       " 'moving_van',\n",
       " 'muzzle',\n",
       " 'nail',\n",
       " 'neck_brace',\n",
       " 'necklace',\n",
       " 'nipple',\n",
       " 'notebook',\n",
       " 'obelisk',\n",
       " 'oboe',\n",
       " 'ocarina',\n",
       " 'odometer',\n",
       " 'oil_filter',\n",
       " 'organ',\n",
       " 'oscilloscope',\n",
       " 'overskirt',\n",
       " 'oxcart',\n",
       " 'oxygen_mask',\n",
       " 'packet',\n",
       " 'paddle',\n",
       " 'paddlewheel',\n",
       " 'padlock',\n",
       " 'paintbrush',\n",
       " 'pajama',\n",
       " 'palace',\n",
       " 'panpipe',\n",
       " 'paper_towel',\n",
       " 'parachute',\n",
       " 'parallel_bars',\n",
       " 'park_bench',\n",
       " 'parking_meter',\n",
       " 'passenger_car',\n",
       " 'patio',\n",
       " 'pay-phone',\n",
       " 'pedestal',\n",
       " 'pencil_box',\n",
       " 'pencil_sharpener',\n",
       " 'perfume',\n",
       " 'Petri_dish',\n",
       " 'photocopier',\n",
       " 'pick',\n",
       " 'pickelhaube',\n",
       " 'picket_fence',\n",
       " 'pickup',\n",
       " 'pier',\n",
       " 'piggy_bank',\n",
       " 'pill_bottle',\n",
       " 'pillow',\n",
       " 'ping-pong_ball',\n",
       " 'pinwheel',\n",
       " 'pirate',\n",
       " 'pitcher',\n",
       " 'plane',\n",
       " 'planetarium',\n",
       " 'plastic_bag',\n",
       " 'plate_rack',\n",
       " 'plow',\n",
       " 'plunger',\n",
       " 'Polaroid_camera',\n",
       " 'pole',\n",
       " 'police_van',\n",
       " 'poncho',\n",
       " 'pool_table',\n",
       " 'pop_bottle',\n",
       " 'pot',\n",
       " \"potter's_wheel\",\n",
       " 'power_drill',\n",
       " 'prayer_rug',\n",
       " 'printer',\n",
       " 'prison',\n",
       " 'projectile',\n",
       " 'projector',\n",
       " 'puck',\n",
       " 'punching_bag',\n",
       " 'purse',\n",
       " 'quill',\n",
       " 'quilt',\n",
       " 'racer',\n",
       " 'racket',\n",
       " 'radiator',\n",
       " 'radio',\n",
       " 'radio_telescope',\n",
       " 'rain_barrel',\n",
       " 'recreational_vehicle',\n",
       " 'reel',\n",
       " 'reflex_camera',\n",
       " 'refrigerator',\n",
       " 'remote_control',\n",
       " 'restaurant',\n",
       " 'revolver',\n",
       " 'rifle',\n",
       " 'rocking_chair',\n",
       " 'rotisserie',\n",
       " 'rubber_eraser',\n",
       " 'rugby_ball',\n",
       " 'rule',\n",
       " 'running_shoe',\n",
       " 'safe',\n",
       " 'safety_pin',\n",
       " 'saltshaker',\n",
       " 'sandal',\n",
       " 'sarong',\n",
       " 'sax',\n",
       " 'scabbard',\n",
       " 'scale',\n",
       " 'school_bus',\n",
       " 'schooner',\n",
       " 'scoreboard',\n",
       " 'screen',\n",
       " 'screw',\n",
       " 'screwdriver',\n",
       " 'seat_belt',\n",
       " 'sewing_machine',\n",
       " 'shield',\n",
       " 'shoe_shop',\n",
       " 'shoji',\n",
       " 'shopping_basket',\n",
       " 'shopping_cart',\n",
       " 'shovel',\n",
       " 'shower_cap',\n",
       " 'shower_curtain',\n",
       " 'ski',\n",
       " 'ski_mask',\n",
       " 'sleeping_bag',\n",
       " 'slide_rule',\n",
       " 'sliding_door',\n",
       " 'slot',\n",
       " 'snorkel',\n",
       " 'snowmobile',\n",
       " 'snowplow',\n",
       " 'soap_dispenser',\n",
       " 'soccer_ball',\n",
       " 'sock',\n",
       " 'solar_dish',\n",
       " 'sombrero',\n",
       " 'soup_bowl',\n",
       " 'space_bar',\n",
       " 'space_heater',\n",
       " 'space_shuttle',\n",
       " 'spatula',\n",
       " 'speedboat',\n",
       " 'spider_web',\n",
       " 'spindle',\n",
       " 'sports_car',\n",
       " 'spotlight',\n",
       " 'stage',\n",
       " 'steam_locomotive',\n",
       " 'steel_arch_bridge',\n",
       " 'steel_drum',\n",
       " 'stethoscope',\n",
       " 'stole',\n",
       " 'stone_wall',\n",
       " 'stopwatch',\n",
       " 'stove',\n",
       " 'strainer',\n",
       " 'streetcar',\n",
       " 'stretcher',\n",
       " 'studio_couch',\n",
       " 'stupa',\n",
       " 'submarine',\n",
       " 'suit',\n",
       " 'sundial',\n",
       " 'sunglass',\n",
       " 'sunglasses',\n",
       " 'sunscreen',\n",
       " 'suspension_bridge',\n",
       " 'swab',\n",
       " 'sweatshirt',\n",
       " 'swimming_trunks',\n",
       " 'swing',\n",
       " 'switch',\n",
       " 'syringe',\n",
       " 'table_lamp',\n",
       " 'tank',\n",
       " 'tape_player',\n",
       " 'teapot',\n",
       " 'teddy',\n",
       " 'television',\n",
       " 'tennis_ball',\n",
       " 'thatch',\n",
       " 'theater_curtain',\n",
       " 'thimble',\n",
       " 'thresher',\n",
       " 'throne',\n",
       " 'tile_roof',\n",
       " 'toaster',\n",
       " 'tobacco_shop',\n",
       " 'toilet_seat',\n",
       " 'torch',\n",
       " 'totem_pole',\n",
       " 'tow_truck',\n",
       " 'toyshop',\n",
       " 'tractor',\n",
       " 'trailer_truck',\n",
       " 'tray',\n",
       " 'trench_coat',\n",
       " 'tricycle',\n",
       " 'trimaran',\n",
       " 'tripod',\n",
       " 'triumphal_arch',\n",
       " 'trolleybus',\n",
       " 'trombone',\n",
       " 'tub',\n",
       " 'turnstile',\n",
       " 'typewriter_keyboard',\n",
       " 'umbrella',\n",
       " 'unicycle',\n",
       " 'upright',\n",
       " 'vacuum',\n",
       " 'vase',\n",
       " 'vault',\n",
       " 'velvet',\n",
       " 'vending_machine',\n",
       " 'vestment',\n",
       " 'viaduct',\n",
       " 'violin',\n",
       " 'volleyball',\n",
       " 'waffle_iron',\n",
       " 'wall_clock',\n",
       " 'wallet',\n",
       " 'wardrobe',\n",
       " 'warplane',\n",
       " 'washbasin',\n",
       " 'washer',\n",
       " 'water_bottle',\n",
       " 'water_jug',\n",
       " 'water_tower',\n",
       " 'whiskey_jug',\n",
       " 'whistle',\n",
       " 'wig',\n",
       " 'window_screen',\n",
       " 'window_shade',\n",
       " 'Windsor_tie',\n",
       " 'wine_bottle',\n",
       " 'wing',\n",
       " 'wok',\n",
       " 'wooden_spoon',\n",
       " 'wool',\n",
       " 'worm_fence',\n",
       " 'wreck',\n",
       " 'yawl',\n",
       " 'yurt',\n",
       " 'web_site',\n",
       " 'comic_book',\n",
       " 'crossword_puzzle',\n",
       " 'street_sign',\n",
       " 'traffic_light',\n",
       " 'book_jacket',\n",
       " 'menu',\n",
       " 'plate',\n",
       " 'guacamole',\n",
       " 'consomme',\n",
       " 'hot_pot',\n",
       " 'trifle',\n",
       " 'ice_cream',\n",
       " 'ice_lolly',\n",
       " 'French_loaf',\n",
       " 'bagel',\n",
       " 'pretzel',\n",
       " 'cheeseburger',\n",
       " 'hotdog',\n",
       " 'mashed_potato',\n",
       " 'head_cabbage',\n",
       " 'broccoli',\n",
       " 'cauliflower',\n",
       " 'zucchini',\n",
       " 'spaghetti_squash',\n",
       " 'acorn_squash',\n",
       " 'butternut_squash',\n",
       " 'cucumber',\n",
       " 'artichoke',\n",
       " 'bell_pepper',\n",
       " 'cardoon',\n",
       " 'mushroom',\n",
       " 'Granny_Smith',\n",
       " 'strawberry',\n",
       " 'orange',\n",
       " 'lemon',\n",
       " 'fig',\n",
       " 'pineapple',\n",
       " 'banana',\n",
       " 'jackfruit',\n",
       " 'custard_apple',\n",
       " 'pomegranate',\n",
       " 'hay',\n",
       " 'carbonara',\n",
       " 'chocolate_sauce',\n",
       " 'dough',\n",
       " 'meat_loaf',\n",
       " 'pizza',\n",
       " 'potpie',\n",
       " 'burrito',\n",
       " 'red_wine',\n",
       " 'espresso',\n",
       " 'cup',\n",
       " 'eggnog',\n",
       " 'alp',\n",
       " 'bubble',\n",
       " 'cliff',\n",
       " 'coral_reef',\n",
       " 'geyser',\n",
       " 'lakeside',\n",
       " 'promontory',\n",
       " 'sandbar',\n",
       " 'seashore',\n",
       " 'valley',\n",
       " 'volcano',\n",
       " 'ballplayer',\n",
       " 'groom',\n",
       " 'scuba_diver',\n",
       " 'rapeseed',\n",
       " 'daisy',\n",
       " \"yellow_lady's_slipper\",\n",
       " 'corn',\n",
       " 'acorn',\n",
       " 'hip',\n",
       " 'buckeye',\n",
       " 'coral_fungus',\n",
       " 'agaric',\n",
       " 'gyromitra',\n",
       " 'stinkhorn',\n",
       " 'earthstar',\n",
       " 'hen-of-the-woods',\n",
       " 'bolete',\n",
       " 'ear',\n",
       " 'toilet_tissue']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imsave(img, img_path):\n",
    "    npimg = img.numpy()\n",
    "#     plt.imshow(np.transpose(npimg,(1,2,0)))\n",
    "    plt.imsave(img_path, np.transpose(npimg,(1,2,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inv_transforms = torch.nn.Sequential(\n",
    "#             transforms.Normalize(mean=[ 0., 0., 0. ], std=[ 1/0.229, 1/0.224, 1/0.225 ]),\n",
    "#             transforms.Normalize(mean=[ -0.485, -0.456, -0.406 ], std=[ 1., 1., 1.] )\n",
    "#         )\n",
    "# denormalize = torch.jit.script(inv_transforms)\n",
    "from timm.data.constants import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD\n",
    "from torchvision.transforms import ToPILImage\n",
    "val_dataset = torchvision.datasets.ImageFolder(root=os.path.join(imagenet_path, 'val'), transform=plain_transforms)\n",
    "val_dataset_loader = data.DataLoader(val_dataset, batch_size=1, shuffle=False, drop_last=False, num_workers=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.485, 0.456, 0.406)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMAGENET_DEFAULT_MEAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.2290]],\n",
      "\n",
      "         [[0.2240]],\n",
      "\n",
      "         [[0.2250]]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "IMAGENET_DEFAULT_STD\n",
    "std = torch.as_tensor(IMAGENET_DEFAULT_STD).to(device)[None, :, None, None]\n",
    "print(std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adversarial Image & Predicted Label\n",
      "----------------------------------------------------------------------\n",
      "FGSM(model_name=ResNet, device=cuda:0, eps=0.06274509803921569, attack_mode=default, return_type=float)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca8eeee3b8fb4b9287d995b95b737fe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Adversarial Image & Predicted Label\")\n",
    "save_root_path = \"c:/users/Albert Wen/ml_security/Attack\"\n",
    "\n",
    "for atk in atks :\n",
    "    \n",
    "    print(\"-\"*70)\n",
    "    print(atk)\n",
    "    \n",
    "    save_attack_folder = os.path.join(save_root_path, 'fgsm_16')\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    start = time.time()\n",
    "    count = 0\n",
    "#     with tqdm(val_dataset_loader, unit=\" batch\") as tepoch:\n",
    "#         for images, labels in tepoch:\n",
    "    for i, (images, labels) in enumerate(tqdm(val_dataset_loader)):\n",
    "\n",
    "        labels = labels.to(device)\n",
    "        cls_idx = class_idx[str(labels.item())][0]\n",
    "\n",
    "        folderExists = os.path.exists(os.path.join(save_attack_folder, cls_idx))\n",
    "        if folderExists == False:\n",
    "            os.mkdir(os.path.join(save_attack_folder, cls_idx))\n",
    "\n",
    "        adv_images = atk(images, labels)\n",
    "\n",
    "        outputs = pretrained_model(adv_images)\n",
    "\n",
    "        _, pre = torch.max(outputs.data, 1)\n",
    "\n",
    "        total += images.shape[0]\n",
    "        correct += (pre == labels).sum()\n",
    "\n",
    "        img_file_path = os.path.join(save_attack_folder, cls_idx) + '/' + cls_idx + '_' + str(i).zfill(5) + '.JPEG'\n",
    "\n",
    "    #         mean = torch.as_tensor(IMAGENET_DEFAULT_MEAN).to(device)[None, :, None, None]\n",
    "    #         std = torch.as_tensor(IMAGENET_DEFAULT_STD).to(device)[None, :, None, None]\n",
    "    #         unnorm_images = adv_images * std + mean\n",
    "    #         print(adv_images.max())\n",
    "    #         print(adv_images.min())\n",
    "    #         print(unnorm_images.shape)\n",
    "#             pil_img = ToPILImage()(adv_images[0, :])\n",
    "#             pil_img.save(img_file_path)\n",
    "        imsave(adv_images.cpu().data[0], img_file_path)\n",
    "        count += 1\n",
    "        # tepoch.set_postfix(accuracy=(correct.item()/total))\n",
    "\n",
    "\n",
    "    #         imshow(torchvision.utils.make_grid(adv_images.cpu().data, normalize=True), [imagnet_data.classes[i] for i in pre])\n",
    "\n",
    "print('Total elapsed time (sec): %.2f' % (time.time() - start))\n",
    "print('Robust accuracy: %.2f %%' % (100 * float(correct) / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean and Std from ImageNet\n",
    "# NORM_MEAN = np.array([0.485, 0.456, 0.406])\n",
    "# NORM_STD = np.array([0.229, 0.224, 0.225])\n",
    "# from timm.data.constants import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD\n",
    "# No resizing and center crop necessary as images are already preprocessed.\n",
    "unorm_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize(256), transforms.CenterCrop(224),\n",
    "    transforms.Normalize(IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD)\n",
    "])\n",
    "attack_imagenet_path = 'c:/users/Albert Wen/ml_security/Attack/'\n",
    "attack_val_dataset = torchvision.datasets.ImageFolder(root=os.path.join(attack_imagenet_path, 'fgsm_16'), transform=unorm_transforms)\n",
    "attack_dataset_loader = data.DataLoader(attack_val_dataset, batch_size=32, shuffle=False, drop_last=False, num_workers=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adversarial Image & Predicted Label\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eedf3fb7e5224d39acd9d4b196c51d6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total elapsed time (sec): 118.90\n",
      "Robust accuracy: 23.94 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Adversarial Image & Predicted Label\")\n",
    "save_root_path = \"c:/users/Albert Wen/ml_security/Attack\"\n",
    "    \n",
    "save_attack_folder = os.path.join(save_root_path, 'fgsm_16')\n",
    "    \n",
    "correct = 0\n",
    "total = 0\n",
    "start = time.time()\n",
    "    \n",
    "for i, (images, labels) in enumerate(tqdm(attack_dataset_loader)):\n",
    "    \n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "    \n",
    "    outputs = pretrained_model(images)\n",
    "\n",
    "    _, pre = torch.max(outputs.data, 1)\n",
    "\n",
    "    total += images.shape[0]\n",
    "    correct += (pre == labels).sum()\n",
    "        \n",
    "#         img_file_path = os.path.join(save_attack_folder, cls_idx) + '/' + cls_idx + '_' + str(i).zfill(5) + '.JPEG'\n",
    "        \n",
    "#         imsave(adv_images.cpu().data[0], img_file_path)\n",
    "\n",
    "#         imshow(torchvision.utils.make_grid(adv_images.cpu().data, normalize=True), [imagnet_data.classes[i] for i in pre])\n",
    "\n",
    "print('Total elapsed time (sec): %.2f' % (time.time() - start))\n",
    "print('Robust accuracy: %.2f %%' % (100 * float(correct) / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> load chechpoint found at c:/users/Albert Wen/resnet50.pth\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5           [-1, 64, 56, 56]           4,096\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "              ReLU-7           [-1, 64, 56, 56]               0\n",
      "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
      "             ReLU-10           [-1, 64, 56, 56]               0\n",
      "           Conv2d-11          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-12          [-1, 256, 56, 56]             512\n",
      "           Conv2d-13          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-14          [-1, 256, 56, 56]             512\n",
      "             ReLU-15          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-16          [-1, 256, 56, 56]               0\n",
      "           Conv2d-17           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-18           [-1, 64, 56, 56]             128\n",
      "             ReLU-19           [-1, 64, 56, 56]               0\n",
      "           Conv2d-20           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-21           [-1, 64, 56, 56]             128\n",
      "             ReLU-22           [-1, 64, 56, 56]               0\n",
      "           Conv2d-23          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-24          [-1, 256, 56, 56]             512\n",
      "             ReLU-25          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-26          [-1, 256, 56, 56]               0\n",
      "           Conv2d-27           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-28           [-1, 64, 56, 56]             128\n",
      "             ReLU-29           [-1, 64, 56, 56]               0\n",
      "           Conv2d-30           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-31           [-1, 64, 56, 56]             128\n",
      "             ReLU-32           [-1, 64, 56, 56]               0\n",
      "           Conv2d-33          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-34          [-1, 256, 56, 56]             512\n",
      "             ReLU-35          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-36          [-1, 256, 56, 56]               0\n",
      "           Conv2d-37          [-1, 128, 56, 56]          32,768\n",
      "      BatchNorm2d-38          [-1, 128, 56, 56]             256\n",
      "             ReLU-39          [-1, 128, 56, 56]               0\n",
      "           Conv2d-40          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-41          [-1, 128, 28, 28]             256\n",
      "             ReLU-42          [-1, 128, 28, 28]               0\n",
      "           Conv2d-43          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-44          [-1, 512, 28, 28]           1,024\n",
      "           Conv2d-45          [-1, 512, 28, 28]         131,072\n",
      "      BatchNorm2d-46          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-47          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-48          [-1, 512, 28, 28]               0\n",
      "           Conv2d-49          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-50          [-1, 128, 28, 28]             256\n",
      "             ReLU-51          [-1, 128, 28, 28]               0\n",
      "           Conv2d-52          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-53          [-1, 128, 28, 28]             256\n",
      "             ReLU-54          [-1, 128, 28, 28]               0\n",
      "           Conv2d-55          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-56          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-57          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-58          [-1, 512, 28, 28]               0\n",
      "           Conv2d-59          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-60          [-1, 128, 28, 28]             256\n",
      "             ReLU-61          [-1, 128, 28, 28]               0\n",
      "           Conv2d-62          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-63          [-1, 128, 28, 28]             256\n",
      "             ReLU-64          [-1, 128, 28, 28]               0\n",
      "           Conv2d-65          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-66          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-67          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-68          [-1, 512, 28, 28]               0\n",
      "           Conv2d-69          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-70          [-1, 128, 28, 28]             256\n",
      "             ReLU-71          [-1, 128, 28, 28]               0\n",
      "           Conv2d-72          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-73          [-1, 128, 28, 28]             256\n",
      "             ReLU-74          [-1, 128, 28, 28]               0\n",
      "           Conv2d-75          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-76          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-77          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-78          [-1, 512, 28, 28]               0\n",
      "           Conv2d-79          [-1, 256, 28, 28]         131,072\n",
      "      BatchNorm2d-80          [-1, 256, 28, 28]             512\n",
      "             ReLU-81          [-1, 256, 28, 28]               0\n",
      "           Conv2d-82          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-83          [-1, 256, 14, 14]             512\n",
      "             ReLU-84          [-1, 256, 14, 14]               0\n",
      "           Conv2d-85         [-1, 1024, 14, 14]         262,144\n",
      "      BatchNorm2d-86         [-1, 1024, 14, 14]           2,048\n",
      "           Conv2d-87         [-1, 1024, 14, 14]         524,288\n",
      "      BatchNorm2d-88         [-1, 1024, 14, 14]           2,048\n",
      "             ReLU-89         [-1, 1024, 14, 14]               0\n",
      "       Bottleneck-90         [-1, 1024, 14, 14]               0\n",
      "           Conv2d-91          [-1, 256, 14, 14]         262,144\n",
      "      BatchNorm2d-92          [-1, 256, 14, 14]             512\n",
      "             ReLU-93          [-1, 256, 14, 14]               0\n",
      "           Conv2d-94          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-95          [-1, 256, 14, 14]             512\n",
      "             ReLU-96          [-1, 256, 14, 14]               0\n",
      "           Conv2d-97         [-1, 1024, 14, 14]         262,144\n",
      "      BatchNorm2d-98         [-1, 1024, 14, 14]           2,048\n",
      "             ReLU-99         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-100         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-101          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-102          [-1, 256, 14, 14]             512\n",
      "            ReLU-103          [-1, 256, 14, 14]               0\n",
      "          Conv2d-104          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-105          [-1, 256, 14, 14]             512\n",
      "            ReLU-106          [-1, 256, 14, 14]               0\n",
      "          Conv2d-107         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-108         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-109         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-110         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-111          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-112          [-1, 256, 14, 14]             512\n",
      "            ReLU-113          [-1, 256, 14, 14]               0\n",
      "          Conv2d-114          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-115          [-1, 256, 14, 14]             512\n",
      "            ReLU-116          [-1, 256, 14, 14]               0\n",
      "          Conv2d-117         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-118         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-119         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-120         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-121          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-122          [-1, 256, 14, 14]             512\n",
      "            ReLU-123          [-1, 256, 14, 14]               0\n",
      "          Conv2d-124          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-125          [-1, 256, 14, 14]             512\n",
      "            ReLU-126          [-1, 256, 14, 14]               0\n",
      "          Conv2d-127         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-129         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-130         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-131          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-132          [-1, 256, 14, 14]             512\n",
      "            ReLU-133          [-1, 256, 14, 14]               0\n",
      "          Conv2d-134          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-135          [-1, 256, 14, 14]             512\n",
      "            ReLU-136          [-1, 256, 14, 14]               0\n",
      "          Conv2d-137         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-138         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-139         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-140         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-141          [-1, 512, 14, 14]         524,288\n",
      "     BatchNorm2d-142          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-143          [-1, 512, 14, 14]               0\n",
      "          Conv2d-144            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-145            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-146            [-1, 512, 7, 7]               0\n",
      "          Conv2d-147           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-148           [-1, 2048, 7, 7]           4,096\n",
      "          Conv2d-149           [-1, 2048, 7, 7]       2,097,152\n",
      "     BatchNorm2d-150           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-151           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-152           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-153            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-154            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-155            [-1, 512, 7, 7]               0\n",
      "          Conv2d-156            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-157            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-158            [-1, 512, 7, 7]               0\n",
      "          Conv2d-159           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-160           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-161           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-162           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-163            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-164            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-165            [-1, 512, 7, 7]               0\n",
      "          Conv2d-166            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-167            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-168            [-1, 512, 7, 7]               0\n",
      "          Conv2d-169           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-170           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-171           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-172           [-1, 2048, 7, 7]               0\n",
      "AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n",
      "          Linear-174                 [-1, 1000]       2,049,000\n",
      "================================================================\n",
      "Total params: 25,557,032\n",
      "Trainable params: 0\n",
      "Non-trainable params: 25,557,032\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 286.56\n",
      "Params size (MB): 97.49\n",
      "Estimated Total Size (MB): 384.62\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54b43e48b0dd49a5bc4e3ee7afdd814f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating...:   0%|          | 0/1563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 acc: 54.57%\n",
      "Top-5 acc: 79.34%\n",
      "tensor([[[[0.2290]],\n",
      "\n",
      "         [[0.2240]],\n",
      "\n",
      "         [[0.2250]]]], device='cuda:0')\n",
      "Adversarial Image & Predicted Label\n",
      "----------------------------------------------------------------------\n",
      "PGD(model_name=ResNet, device=cuda:0, eps=0.06274509803921569, alpha=0.008888888888888889, steps=10, random_start=False, attack_mode=default, return_type=float)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29db153bc3e243bebdcee583539914e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------\n",
      "PGD(model_name=ResNet, device=cuda:0, eps=0.047058823529411764, alpha=0.008888888888888889, steps=10, random_start=False, attack_mode=default, return_type=float)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f5f770aebf644bab4d84f66dd0b2947",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total elapsed time (sec): 10631.83\n",
      "Robust accuracy: 0.00 %\n"
     ]
    }
   ],
   "source": [
    "pretrained_model = torchvision.models.resnet50(pretrained=True)\n",
    "pretrained_model = pretrained_model.to(device)\n",
    "\n",
    "if CHECKPOINT_PATH:\n",
    "    if os.path.isfile(CHECKPOINT_PATH):\n",
    "        checkpoint = torch.load(CHECKPOINT_PATH) \n",
    "        # model.load_state_dict(checkpoint['state_dict'])  #['state_dict']\n",
    "        pretrained_model.load_state_dict(checkpoint)  #['state_dict']\n",
    "        print(\"=> load chechpoint found at {}\".format(CHECKPOINT_PATH))\n",
    "        # print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "        #       .format(args.resume, checkpoint['epoch']))\n",
    "    else:\n",
    "        print(\"=> no checkpoint found at '{}'\".format(CHECKPOINT_PATH))\n",
    "# No gradients needed for the network\n",
    "pretrained_model.eval()\n",
    "for p in pretrained_model.parameters():\n",
    "    p.requires_grad = False\n",
    "from torchsummary import summary\n",
    "summary(pretrained_model, (3,224,224))\n",
    "\n",
    "from timm.data.constants import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD\n",
    "# No resizing and center crop necessary as images are already preprocessed.\n",
    "plain_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize(256), transforms.CenterCrop(224),\n",
    "#     transforms.Normalize(IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD)\n",
    "])\n",
    "import torchvision.datasets as dsets  \n",
    "def image_folder_custom_label(root, transform, idx2label) :\n",
    "    \n",
    "    old_data = dsets.ImageFolder(root=root, transform=transform)\n",
    "    old_classes = old_data.classes\n",
    "    \n",
    "    label2idx = {}\n",
    "    \n",
    "    for i, item in enumerate(idx2label) :\n",
    " \n",
    "        label2idx[item] = old_classes[i]\n",
    "    \n",
    "    key_list = list(label2idx.keys())\n",
    "    val_list = list(label2idx.values())\n",
    "    \n",
    "    new_data = dsets.ImageFolder(root=root, transform=transform, \n",
    "                                 target_transform=lambda x :  key_list[val_list.index(old_classes[x])])\n",
    "    new_data.classes = idx2label\n",
    "    new_data.class_to_idx = label2idx\n",
    "\n",
    "    return new_data\n",
    "# https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json\n",
    "class_idx = json.load(open(\"./imagenet_class_index.json\"))\n",
    "idx2label = [class_idx[str(k)][1] for k in range(len(class_idx))]\n",
    "from utils import imshow\n",
    "# Load dataset and create data loader\n",
    "imagenet_path = os.path.join(DATASET_PATH, \"ImageNet-Data\")\n",
    "assert os.path.isdir(imagenet_path), f\"Could not find the ImageNet dataset at expected path \\\"{imagenet_path}\\\". \" + \\\n",
    "                                     f\"Please make sure to have downloaded the ImageNet dataset here, or change the {DATASET_PATH=} variable.\"\n",
    "\n",
    "val_dataset = torchvision.datasets.ImageFolder(root=os.path.join(imagenet_path, 'val'), transform=plain_transforms)\n",
    "val_dataset_loader = data.DataLoader(val_dataset, batch_size=32, shuffle=False, drop_last=False, num_workers=5)\n",
    "\n",
    "imagenet_data = image_folder_custom_label(root=os.path.join(imagenet_path, 'val'), transform=plain_transforms, idx2label=idx2label)\n",
    "data_loader = torch.utils.data.DataLoader(imagenet_data, batch_size=32, shuffle=False)\n",
    "\n",
    "def eval_model(dataset_loader, img_func=None):\n",
    "    tp, tp_5, counter = 0., 0., 0.\n",
    "    for imgs, labels in tqdm(dataset_loader, desc=\"Validating...\"):\n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        if img_func is not None:\n",
    "            imgs = img_func(imgs, labels)\n",
    "        with torch.no_grad():\n",
    "            preds = pretrained_model(imgs)\n",
    "        tp += (preds.argmax(dim=-1) == labels).sum()\n",
    "        tp_5 += (preds.topk(5, dim=-1)[1] == labels[...,None]).any(dim=-1).sum()\n",
    "        counter += preds.shape[0]\n",
    "    acc = tp.float().item()/counter\n",
    "    top5 = tp_5.float().item()/counter\n",
    "    print(f\"Top-1 acc: {(100.0 * (acc)):4.2f}%\")\n",
    "    print(f\"Top-5 acc: {(100.0 * (top5)):4.2f}%\")\n",
    "    return acc, top5\n",
    "_ = eval_model(val_dataset_loader)\n",
    "from torchattacks import *\n",
    "atks = [\n",
    "    # FGSM(pretrained_model, eps=4/255)\n",
    "#     FGSM(pretrained_model, eps=8/255),\n",
    "    # FGSM(pretrained_model, eps=16/255),\n",
    "    # BIM(pretrained_model, eps=8/255, alpha=2/255, steps=10),\n",
    "    # RFGSM(pretrained_model, eps=8/255, alpha=2/255, steps=100),\n",
    "    # CW(pretrained_model, c=1, lr=0.01, steps=10, kappa=0),\n",
    "    PGD(pretrained_model, eps=16/255, alpha=2/225, steps=10,random_start=False),\n",
    "    PGD(pretrained_model, eps=12/255, alpha=2/225, steps=10,random_start=False),\n",
    "\n",
    "    # PGDL2(pretrained_model, eps=1, alpha=0.2, steps=10),\n",
    "    # EOTPGD(pretrained_model, eps=8/255, alpha=2/255, steps=100, eot_iter=2),\n",
    "    # FFGSM(pretrained_model, eps=8/255, alpha=10/255),\n",
    "    # TPGD(pretrained_model, eps=8/255, alpha=2/255, steps=100),\n",
    "    # MIFGSM(pretrained_model, eps=8/255, alpha=2/255, steps=100, decay=0.1),\n",
    "    # VANILA(pretrained_model),\n",
    "    # GN(pretrained_model, std=0.1),\n",
    "    # APGD(pretrained_model, eps=8/255, steps=100, eot_iter=1, n_restarts=1, loss='ce'),\n",
    "    # APGD(pretrained_model, eps=8/255, steps=10, eot_iter=1, n_restarts=1, loss='dlr'),\n",
    "    # APGDT(pretrained_model, eps=8/255, steps=100, eot_iter=1, n_restarts=1),\n",
    "    # FAB(pretrained_model, eps=8/255, steps=100, n_classes=10, n_restarts=1, targeted=False),\n",
    "    # FAB(pretrained_model, eps=8/255, steps=100, n_classes=10, n_restarts=1, targeted=True),\n",
    "    # Square(pretrained_model, eps=8/255, n_queries=5000, n_restarts=1, loss='ce'),\n",
    "    # AutoAttack(pretrained_model, eps=8/255, n_classes=10, version='standard'),\n",
    "    # OnePixel(pretrained_model, pixels=5, steps=10, inf_batch=50),\n",
    "    # DeepFool(pretrained_model, steps=10),\n",
    "    # DIFGSM(pretrained_model, eps=8/255, alpha=2/255, steps=100, diversity_prob=0.5, resize_rate=0.9)\n",
    "    #   Pixle(pretrained_model, x_dimensions=(0.1, 0.2), restarts=10, max_iterations=10)\n",
    "]\n",
    "# atk_names = [\"bim_2\", \"rfgsm_8\", \"cw_1\", \"pgd_8\", \"pgdl2_1\", \"eotpgd_8\", \"ffgsm_8\", \"tpgd_8\", \"mifgsm_8\", \n",
    "#     \"vanilla\", \"gn\", \"apgd_8_100\", \"apgd_8_10\", \"apgdt_8\", \"fab_not_targeted\", \"fab_targeted\", \"square\", \n",
    "#     \"autoattack\", \"onepixel\", \"deepfool\", \"difgsm_8\"]\n",
    "atk_names = [\"pgd_16\", \"pgd_12\"]\n",
    "\n",
    "def imsave(img, img_path):\n",
    "    npimg = img.numpy()\n",
    "#     plt.imshow(np.transpose(npimg,(1,2,0)))\n",
    "    plt.imsave(img_path, np.transpose(npimg,(1,2,0)))\n",
    "# inv_transforms = torch.nn.Sequential(\n",
    "#             transforms.Normalize(mean=[ 0., 0., 0. ], std=[ 1/0.229, 1/0.224, 1/0.225 ]),\n",
    "#             transforms.Normalize(mean=[ -0.485, -0.456, -0.406 ], std=[ 1., 1., 1.] )\n",
    "#         )\n",
    "# denormalize = torch.jit.script(inv_transforms)\n",
    "from timm.data.constants import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD\n",
    "from torchvision.transforms import ToPILImage\n",
    "val_dataset = torchvision.datasets.ImageFolder(root=os.path.join(imagenet_path, 'val'), transform=plain_transforms)\n",
    "val_dataset_loader = data.DataLoader(val_dataset, batch_size=1, shuffle=False, drop_last=False, num_workers=5)\n",
    "# IMAGENET_DEFAULT_MEAN\n",
    "# IMAGENET_DEFAULT_STD\n",
    "std = torch.as_tensor(IMAGENET_DEFAULT_STD).to(device)[None, :, None, None]\n",
    "print(std)\n",
    "print(\"Adversarial Image & Predicted Label\")\n",
    "save_root_path = \"c:/users/Albert Wen/ml_security/Attack\"\n",
    "\n",
    "for i in range(len(atks)) :\n",
    "    atk = atks[i]\n",
    "\n",
    "    print(\"-\"*70)\n",
    "    print(atk)\n",
    "    \n",
    "    if not os.path.exists(os.path.join(save_root_path, atk_names[i])):\n",
    "        os.mkdir(os.path.join(save_root_path, atk_names[i]))\n",
    "    save_attack_folder = os.path.join(save_root_path, atk_names[i])\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    start = time.time()\n",
    "    count = 0\n",
    "#     with tqdm(val_dataset_loader, unit=\" batch\") as tepoch:\n",
    "#         for images, labels in tepoch:\n",
    "    for i, (images, labels) in enumerate(tqdm(val_dataset_loader)):\n",
    "\n",
    "        labels = labels.to(device)\n",
    "        cls_idx = class_idx[str(labels.item())][0]\n",
    "\n",
    "        folderExists = os.path.exists(os.path.join(save_attack_folder, cls_idx))\n",
    "        if folderExists == False:\n",
    "            os.mkdir(os.path.join(save_attack_folder, cls_idx))\n",
    "\n",
    "        adv_images = atk(images, labels)\n",
    "\n",
    "        outputs = pretrained_model(adv_images)\n",
    "\n",
    "        _, pre = torch.max(outputs.data, 1)\n",
    "\n",
    "        total += images.shape[0]\n",
    "        correct += (pre == labels).sum()\n",
    "\n",
    "        img_file_path = os.path.join(save_attack_folder, cls_idx) + '/' + cls_idx + '_' + str(i).zfill(5) + '.JPEG'\n",
    "\n",
    "        imsave(adv_images.cpu().data[0], img_file_path)\n",
    "        count += 1\n",
    "        \n",
    "print('Total elapsed time (sec): %.2f' % (time.time() - start))\n",
    "print('Robust accuracy: %.2f %%' % (100 * float(correct) / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "c09d1698212c735a3443dc0423fe58b563a1b228e762256a81505a70ae1393dc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
